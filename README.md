# GFlowFuzz: Diversity-Promoting Fuzzing with Generative Flow Networks 

(Repo Implementation in Progress)

**GFlowFuzz** is a novel LLM-driven fuzzing framework that integrates **Generative Flow Networks (GFlowNets)** with large language models to generate **diverse, high-reward fuzz inputs**. It systematically improves code coverage and bug discovery in software testing through a two-phase training procedure that fine-tunes an instruction-generation policy.

---

## üîç Motivation
LLM-based fuzzers often suffer from **mode collapse**, repeatedly producing similar inputs that miss critical edge cases. GFlowFuzz tackles this by optimizing a latent instruction-generation policy with the GFlowNet objective, enabling exploratory, high-reward sampling of fuzzing code conditioned on problem specifications.

---

## üß† Key Components

| Component | Role | Implementation |
|-----------|------|----------------|
| **Distiller (Œ¶<sub>d</sub>)** | AutoPrompting ‚áí distils specs/docs to a concise prompt **X** | GPT-4o |
| **Instructor (Œ¶<sub>g</sub>)** | Generates instruction sequence **Z** given **X** | LoRA-adapted LLM trained with **Trajectory Balance** |
| **Coder (Œ¶<sub>c</sub>)** | Converts *(X, Z)* into executable fuzz code **C** | Code LLM (e.g., StarCoder) |
| **Oracle (ùí™)** | Executes **C** on SUT, returns coverage Œî and crash info | Coverage+bug instrumentation |

---

## üöÄ Training Workflow

### Phase I ‚Äî Exploration
1. **Sample** instruction sequences with the current Instructor policy.  
2. **Generate** fuzz input via the Coder and **execute** on the SUT.  
3. **Compute reward** `R = Œîcoverage + Œª¬∑coverage + Œ≤¬∑1[bug]`.  
4. **Store** trajectories in a replay buffer.  
5. **Update** Instructor by minimizing **SubTB** loss on mixed on-policy + high-reward batches.

### Phase II ‚Äî Exploitation
- **Freeze** the trained policy.  
- **Generate & execute** fuzz inputs for the remaining budget to harvest bugs without additional optimisation overhead.

---

## üßÆ Reward Function

```text
R(C) = Œîcoverage(C) + Œª ¬∑ coverage(C) + Œ≤ ¬∑ 1[bug(C)]
```

## üìÇ Repository Structure

GFlowFuzz/
‚îú‚îÄ‚îÄ distiller/         # Prompt distillation (Œ¶d)
‚îú‚îÄ‚îÄ instructor/        # GFlowNet training for instruction gen (Œ¶g)
‚îú‚îÄ‚îÄ coder/             # Code generation using LLMs (Œ¶c)
‚îú‚îÄ‚îÄ oracle/            # Coverage + bug reward computation
‚îú‚îÄ‚îÄ replay_buffer/     # Trajectory / reward storage
‚îú‚îÄ‚îÄ configs/           # YAML/JSON hyper-params
‚îú‚îÄ‚îÄ scripts/           # Train & evaluate pipelines
‚îú‚îÄ‚îÄ utils/             # Common helpers
‚îî‚îÄ‚îÄ README.md          # ‚Üê you are here!

## Usage

To download the models for the local language model, you need a way to retireve them, either from HuggingFace directly or from a local repository.
To point the program to the right location, you need to set either the environment variable `HUGGING_FACE_HUB_TOKEN` or `HF_HOME`.
See the two examples of `.env` files in the `envs` folder.
Copy one of them in the root directory and rename it `.env`.

You can run the approach either passing the arguments directly to the script or by using a configuration file.

Note that you need to be logged into HuggingFace and have access to `bigcode/starcoderbase` to use the language model
(for both cached locally or from HuggingFace directly)


## üìñ References
- Bengio et al., 2023 ‚Äì GFlowNet Foundations
- Hu et al., 2024 ‚Äì Amortizing Intractable Inference in LLMs
- Lee et al., 2024 ‚Äì Learning Diverse Attacks for Red-Teaming
- Xia et al., 2024 ‚Äì Fuzz4All: Universal Fuzzing with LLMs


## Developer Setup

1. Create a virtual environment (Python 3.10) and install the requirements.
    ```shell
    conda create -n fuzz-everything python=3.10
    ```

2. Activate the environment.
    ```shell
    conda activate fuzz-everything
    ```

3. Install the requirements.
    ```shell
    pip install -r requirements.txt
    pre-commit install
    pip install -e .
    ```

Note: to save the conda environment, run `conda env export > environment.yml` and to load it, run `conda env create -f environment.yml`.

## üìå TODO
- Detailed setup and dependency list
- Pretrained Distiller / Instructor checkpoints
- Automatic coverage instrumentation scripts
- Example fuzzing campaign with sample SUT

## ü§ù Contributing
Contributions are welcome! Please open an issue or pull request to propose features, improvements, or bug fixes.






